{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cbaabe",
   "metadata": {},
   "source": [
    "# Multi-modal news headline generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858155bc",
   "metadata": {},
   "source": [
    "### IMP: Before proceeding with the assignment, I wanted to point out that the task asked for Headline generation. But the datasets attached didn't have a headline column. so, i figured out you mean by headline > Summarization. and I went with this conclusion because of the datasets structure. it includes a normal text and then its summary.\n",
    "\n",
    "#### also to add up to this at once, the datasets also did not include the Images. so I didn't use any images as you can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afaa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a942785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\CompuFast\\.cache\\kagglehub\\datasets\\pariza\\bbc-news-summary\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"pariza/bbc-news-summary\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "base_path = Path(path) / \"BBC News Summary\"\n",
    "articles_path = base_path / \"News Articles\"\n",
    "summaries_path = base_path / \"Summaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ddce5",
   "metadata": {},
   "source": [
    "### reading and extracting the data from the two subfolders I need, Into one pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285479a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    for enc in (\"utf-8\", \"cp1252\", \"latin-1\"):\n",
    "        try:\n",
    "            with open(filepath, \"r\", encoding=enc) as f:\n",
    "                return f.read().strip()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for category in os.listdir(articles_path):\n",
    "    category_articles_path = articles_path / category\n",
    "    category_summaries_path = summaries_path / category\n",
    "    \n",
    "    if not category_articles_path.is_dir():\n",
    "        continue\n",
    "    \n",
    "    for filename in os.listdir(category_articles_path):\n",
    "        article_file = category_articles_path / filename\n",
    "        summary_file = category_summaries_path / filename\n",
    "        \n",
    "        if article_file.is_file() and summary_file.is_file():\n",
    "            article_text = read_file(article_file)\n",
    "            summary_text = read_file(summary_file)\n",
    "            \n",
    "            records.append({\n",
    "                \"article_text\": article_text,\n",
    "                \"summary_text\": summary_text\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21961268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (2225, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>summary_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                        summary_text  \n",
       "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1  The dollar has hit its highest level against t...  \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3  Rod Eddington, BA's chief executive, said the ...  \n",
       "4  Pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a83386",
   "metadata": {},
   "source": [
    "### Comparing the actual text with its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f0a08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      " -------------\n",
      "TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.Time Warner's fourth quarter profits were slightly better than analysts' expectations.\n"
     ]
    }
   ],
   "source": [
    "print(df['article_text'][0] + \"\\n\\n -------------\" \"\\n\"  + df['summary_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad31226",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35937857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_text    0\n",
       "summary_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7ceaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\CompuFast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\CompuFast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\CompuFast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\CompuFast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868246c",
   "metadata": {},
   "source": [
    "#### note: in contrary of what we did in frequency based techniques, here we will actually need to retain the stop words and the words as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4319e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', doc)\n",
    "\n",
    "def case_folding(tokens):\n",
    "    return [word.lower() for word in tokens]\n",
    "\n",
    "def tokenize(doc):\n",
    "    return word_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b248c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(document):\n",
    "    cleaned = clean_text(document)\n",
    "    tokenized = tokenize(cleaned)\n",
    "    tokenized = case_folding(tokenized)\n",
    "    return ' '.join(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c28b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_text'] = df['article_text'].apply(Preprocess)\n",
    "df['summary_text'] = df['summary_text'].apply(Preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00704991",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['article_text']\n",
    "summary = df['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994aa50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad sales boost time warner profit quarterly profits at us media giant timewarner jumped to bn m for the three months to december from m yearearlier the firm which is now one of the biggest investors in google benefited from sales of highspeed internet connections and higher advert sales timewarner said fourth quarter sales rose to bn from bn its profits were buoyed by oneoff gains which offset a profit dip at warner bros and less users for aol time warner said on friday that it now owns of searchengine google but its own internet business aol had has mixed fortunes it lost subscribers in the fourth quarter profits were lower than in the preceding three quarters however the company said aols underlying profit before exceptional items rose on the back of stronger internet advertising revenues it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aols existing customers for highspeed broadband timewarner also has to restate and results following a probe by the us securities exchange commission sec which is close to concluding time warners fourth quarter profits were slightly better than analysts expectations but its film division saw profits slump to m helped by boxoffice flops alexander and catwoman a sharp contrast to yearearlier when the third and final film in the lord of the rings trilogy boosted results for the fullyear timewarner posted a profit of bn up from its performance while revenues grew to bn our financial performance was strong meeting or exceeding all of our fullyear objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said for timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit margins timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators it has already offered to pay m to settle charges in a deal that is under review by the sec the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at m it intends to adjust the way it accounts for a deal with german music publisher bertelsmanns purchase of a stake in aol europe which it had reported as advertising revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\n",
      "\n",
      " -------------\n",
      "timewarner said fourth quarter sales rose to bn from bnfor the fullyear timewarner posted a profit of bn up from its performance while revenues grew to bnquarterly profits at us media giant timewarner jumped to bn m for the three months to december from m yearearlierhowever the company said aols underlying profit before exceptional items rose on the back of stronger internet advertising revenuesits profits were buoyed by oneoff gains which offset a profit dip at warner bros and less users for aolfor timewarner is projecting operating earnings growth of around and also expects higher revenue and wider profit marginsit lost subscribers in the fourth quarter profits were lower than in the preceding three quarterstime warners fourth quarter profits were slightly better than analysts expectations\n"
     ]
    }
   ],
   "source": [
    "print(text[0] + \"\\n\\n -------------\" \"\\n\"  + summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe8b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>summary_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>timewarner said fourth quarter sales rose to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "      <td>the dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "      <td>yukos owner menatep group says it will ask ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit bas profits british airwa...</td>\n",
       "      <td>rod eddington bas chief executive said the res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "      <td>pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "1  dollar gains on greenspan speech the dollar ha...   \n",
       "2  yukos unit buyer faces loan claim the owners o...   \n",
       "3  high fuel prices hit bas profits british airwa...   \n",
       "4  pernod takeover talk lifts domecq shares in uk...   \n",
       "\n",
       "                                        summary_text  \n",
       "0  timewarner said fourth quarter sales rose to b...  \n",
       "1  the dollar has hit its highest level against t...  \n",
       "2  yukos owner menatep group says it will ask ros...  \n",
       "3  rod eddington bas chief executive said the res...  \n",
       "4  pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb46dbe",
   "metadata": {},
   "source": [
    " ## Transformer\n",
    "\n",
    "### Here I used the pipeline library as Im familiar with and it is fast and efficient.\n",
    "### Used this model because of its small size and still efficient performance tailored to this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49778ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      " dollar gains on greenspan speech the dollar has hit its highest level against the euro in almost three months after the federal reserve head said the us trade deficit is set to stabilise and alan greenspan highlighted the us governments willingness to curb spending and rising household savings as factors which may help to reduce it in late trading in new york the dollar reached against the euro from on thursday market concerns about the deficit has hit the greenback in recent months on friday federal reserve chairman mr greenspans speech in london ahead of the meeting of g finance ministers sent the dollar higher after it had earlier tumbled on the back of worsethanexpected us jobs data i think the chairmans taking a much more sanguine view on the current account deficit than hes taken for some time said robert sinche head of currency strategy at bank of america in new york hes taking a longerterm view laying out a set of conditions under which the current account deficit can improve this year and next worries about the deficit concerns about china do however remain chinas currency remains pegged to the dollar and the us currencys sharp falls in recent months have therefore made chinese export prices highly competitive but calls for a shift in beijings policy have fallen on deaf ears despite recent comments in a major chinese newspaper that the time is ripe for a loosening of the peg the g meeting is thought unlikely to produce any meaningful movement in chinese policy in the meantime the us federal reserves decision on february to boost interest rates by a quarter of a point the sixth such move in as many months has opened up a differential with european rates the halfpoint window some believe could be enough to keep us assets looking more attractive and could help prop up the dollar the recent falls have partly been the result of big budget deficits as well as the uss yawning current account gap both of which need to be funded by the buying of us bonds and assets by foreign firms and governments the white house will announce its budget on monday and many commentators believe the deficit will remain at close to half a trillion dollars \n",
      " \n",
      "  ------------- \n",
      " Headline:\n",
      " white house to announce budget on monday and many commentators believe the deficit will remain at close to half a trillion dollars\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\",model=\"google/flan-t5-small\")\n",
    "headline = summarizer(text[1], max_length=35, min_length=20, do_sample=False)\n",
    "print(f\"Original text: \\n {text[1]} \\n \\n ------------- \\n Headline:\\n {headline[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0f21b",
   "metadata": {},
   "source": [
    " ## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28c6a0f",
   "metadata": {},
   "source": [
    "## For our LSTM modeling, we will be using an architecture of encoder and decoder in order to implement a summarization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9395a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c340ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(text, summary,\n",
    "                                       test_size=0.1, random_state=0, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fcbf0",
   "metadata": {},
   "source": [
    "## Pre-modeling procedures including\n",
    "- applying the tokenizer\n",
    "- padding the sequences\n",
    "- defining the sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086eda5c",
   "metadata": {},
   "source": [
    "This code prepares the dataset for the seq2seq model:\n",
    "\n",
    "Adds special **startseq** and *endseq* tokens to every summary so the model knows where a summary begins and ends.\n",
    "\n",
    "Sets vocabulary limits (article_vocab_cap and summary_vocab_cap) to avoid learning rare words.\n",
    "\n",
    "Defines **maximum sequence lengths** for articles and summaries.\n",
    "\n",
    "Tokenizes the articles and summaries, replacing out-of-vocabulary words with <UNK>.\n",
    "\n",
    "Calculates the actual vocabulary sizes to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article vocab: 5000 Summary vocab: 1500\n"
     ]
    }
   ],
   "source": [
    "START, END = \"startseq\", \"endseq\"\n",
    "\n",
    "y_train_proc = [f\"{START} {s} {END}\" for s in y_train]\n",
    "y_test_proc  = [f\"{START} {s} {END}\" for s in y_test]\n",
    "\n",
    "article_vocab_cap = 5000     \n",
    "summary_vocab_cap = 1500\n",
    "article_maxlen = 80          \n",
    "summary_maxlen = 20          \n",
    "latent_dim = 64              \n",
    "embedding_dim = 50\n",
    "\n",
    "article_tok = Tokenizer(num_words=article_vocab_cap, oov_token=\"<UNK>\")\n",
    "article_tok.fit_on_texts(x_train)\n",
    "\n",
    "summary_tok = Tokenizer(num_words=summary_vocab_cap, oov_token=\"<UNK>\")\n",
    "summary_tok.fit_on_texts(y_train_proc)\n",
    "\n",
    "article_vocab_size = min(article_vocab_cap, len(article_tok.word_index) + 1)\n",
    "summary_vocab_size = min(summary_vocab_cap, len(summary_tok.word_index) + 1)\n",
    "print(\"Article vocab:\", article_vocab_size, \"Summary vocab:\", summary_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acf16c",
   "metadata": {},
   "source": [
    "This code transforms the tokenized text into model-ready input:\n",
    "\n",
    "* **Converts** articles and summaries into integer sequences using the fitted tokenizers.\n",
    "* **Pads or truncates** sequences to fixed lengths (article_maxlen and summary_maxlen).\n",
    "* **Splits** summaries into:\n",
    "\n",
    "  * decoder_input > all tokens except the last (fed into the decoder)\n",
    "  * decoder_target > all tokens except the first (what the decoder should predict)\n",
    "* **Creates a mask** to ignore padding (0s) when computing the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes -> X: (2002, 80) DecIn: (2002, 19) DecTgt: (2002, 19)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "X_train_seq = article_tok.texts_to_sequences(x_train)\n",
    "Y_train_seq = summary_tok.texts_to_sequences(y_train_proc)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=article_maxlen, padding='post', truncating='post')\n",
    "Y_train_pad = pad_sequences(Y_train_seq, maxlen=summary_maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Test  \n",
    "X_test_seq  = article_tok.texts_to_sequences(x_test)\n",
    "Y_test_seq  = summary_tok.texts_to_sequences(y_test_proc)\n",
    "X_test_pad  = pad_sequences(X_test_seq,  maxlen=article_maxlen, padding='post', truncating='post')\n",
    "Y_test_pad  = pad_sequences(Y_test_seq,  maxlen=summary_maxlen, padding='post', truncating='post')\n",
    "\n",
    "decoder_input  = Y_train_pad[:, :-1]     \n",
    "decoder_target = Y_train_pad[:, 1:]      \n",
    "print(\"Train shapes -> X:\", X_train_pad.shape, \"DecIn:\", decoder_input.shape, \"DecTgt:\", decoder_target.shape)\n",
    "\n",
    "decoder_target_mask = (decoder_target != 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc28839",
   "metadata": {},
   "source": [
    "## Architecture: \n",
    "It’s a sequence-to-sequence LSTM model for text summarization:\n",
    "the encoder reads the article and produces hidden states,\n",
    "the decoder uses those states to predict the summary word-by-word,\n",
    "and a softmax layer outputs the probability for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ca8e35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">250,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">75,000</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">97,500</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │    \u001b[38;5;34m250,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │     \u001b[38;5;34m75,000\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m29,440\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m29,440\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m1500\u001b[0m)  │     \u001b[38;5;34m97,500\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481,380</span> (1.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m481,380\u001b[0m (1.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481,380</span> (1.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m481,380\u001b[0m (1.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(article_maxlen,))\n",
    "enc_emb = Embedding(article_vocab_cap, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "_, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n",
    "\n",
    "decoder_inputs = Input(shape=(summary_maxlen-1,))\n",
    "dec_emb = Embedding(summary_vocab_cap, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_outputs = LSTM(latent_dim, return_sequences=True)(dec_emb, initial_state=[state_h, state_c])\n",
    "outputs = Dense(summary_vocab_cap, activation='softmax')(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e84748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1922 - loss: 6.9136\n",
      "Epoch 1: val_loss improved from inf to 5.09529, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.1933 - loss: 6.8892 - val_accuracy: 0.2280 - val_loss: 5.0953 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2352 - loss: 5.0356\n",
      "Epoch 2: val_loss improved from 5.09529 to 5.07670, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.2351 - loss: 5.0359 - val_accuracy: 0.2280 - val_loss: 5.0767 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2274 - loss: 5.0598\n",
      "Epoch 3: val_loss did not improve from 5.07670\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2276 - loss: 5.0588 - val_accuracy: 0.2280 - val_loss: 5.0774 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2312 - loss: 5.0206\n",
      "Epoch 4: val_loss improved from 5.07670 to 5.07124, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.2312 - loss: 5.0207 - val_accuracy: 0.2280 - val_loss: 5.0712 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2333 - loss: 5.0014\n",
      "Epoch 5: val_loss improved from 5.07124 to 5.06491, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.2333 - loss: 5.0017 - val_accuracy: 0.2280 - val_loss: 5.0649 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2298 - loss: 5.0191\n",
      "Epoch 6: val_loss improved from 5.06491 to 5.05487, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.2300 - loss: 5.0186 - val_accuracy: 0.2280 - val_loss: 5.0549 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2350 - loss: 4.9733\n",
      "Epoch 7: val_loss improved from 5.05487 to 5.04098, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.2349 - loss: 4.9739 - val_accuracy: 0.2280 - val_loss: 5.0410 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2372 - loss: 4.9424\n",
      "Epoch 8: val_loss improved from 5.04098 to 5.02712, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.2370 - loss: 4.9434 - val_accuracy: 0.2280 - val_loss: 5.0271 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2354 - loss: 4.9374\n",
      "Epoch 9: val_loss improved from 5.02712 to 5.01173, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.2354 - loss: 4.9376 - val_accuracy: 0.2280 - val_loss: 5.0117 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2350 - loss: 4.9150\n",
      "Epoch 10: val_loss improved from 5.01173 to 4.99671, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.2349 - loss: 4.9153 - val_accuracy: 0.2280 - val_loss: 4.9967 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2373 - loss: 4.8879\n",
      "Epoch 11: val_loss improved from 4.99671 to 4.97679, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2371 - loss: 4.8883 - val_accuracy: 0.2280 - val_loss: 4.9768 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2322 - loss: 4.8820\n",
      "Epoch 12: val_loss improved from 4.97679 to 4.95841, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2322 - loss: 4.8817 - val_accuracy: 0.2256 - val_loss: 4.9584 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2332 - loss: 4.8407\n",
      "Epoch 13: val_loss improved from 4.95841 to 4.94097, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2332 - loss: 4.8408 - val_accuracy: 0.2264 - val_loss: 4.9410 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2372 - loss: 4.7965\n",
      "Epoch 14: val_loss improved from 4.94097 to 4.91958, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2371 - loss: 4.7968 - val_accuracy: 0.2303 - val_loss: 4.9196 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2402 - loss: 4.7880\n",
      "Epoch 15: val_loss improved from 4.91958 to 4.90160, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2402 - loss: 4.7880 - val_accuracy: 0.2326 - val_loss: 4.9016 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2449 - loss: 4.7396\n",
      "Epoch 16: val_loss improved from 4.90160 to 4.88496, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2448 - loss: 4.7403 - val_accuracy: 0.2338 - val_loss: 4.8850 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2466 - loss: 4.7008\n",
      "Epoch 17: val_loss improved from 4.88496 to 4.86802, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2465 - loss: 4.7018 - val_accuracy: 0.2336 - val_loss: 4.8680 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2442 - loss: 4.6941\n",
      "Epoch 18: val_loss improved from 4.86802 to 4.85671, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2442 - loss: 4.6942 - val_accuracy: 0.2327 - val_loss: 4.8567 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2518 - loss: 4.6692\n",
      "Epoch 19: val_loss improved from 4.85671 to 4.84190, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2517 - loss: 4.6692 - val_accuracy: 0.2357 - val_loss: 4.8419 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2499 - loss: 4.6551\n",
      "Epoch 20: val_loss improved from 4.84190 to 4.82618, saving model to best_seq2seq.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.2500 - loss: 4.6546 - val_accuracy: 0.2371 - val_loss: 4.8262 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
    "reduce_lr  = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=3e-5, verbose=1)\n",
    "ckpt       = ModelCheckpoint(\"best_seq2seq.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_pad, decoder_input],\n",
    "    decoder_target,                          \n",
    "    sample_weight=decoder_target_mask,        \n",
    "    batch_size=32,\n",
    "    epochs=20,    \n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stop, reduce_lr, ckpt],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c70ef",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08e84464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 summaries...\n",
      "Progress: 0/100\n",
      "Progress: 20/100\n",
      "Progress: 40/100\n",
      "Progress: 60/100\n",
      "Progress: 80/100\n",
      "\n",
      "BLEU Score: 0.0000\n",
      "\n",
      "Example 1:\n",
      "Generated: the <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "Reference: after years of a sagging stock price and a sevenyear hiatus from the ftse one of britains venerable manufacturers has returned to the vaunted index forbes saidthe sugar group had been absent from the ftse for seven years until mr ferguson helped it return to growthtate lyles chief executive has been named european businessman of the year by a leading business magazineiain ferguson was awarded the title by us publication forbes for returning one of the uks venerable manufacturers to the countrys top companies\n",
      "\n",
      "Example 2:\n",
      "Generated: the <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "Reference: record numbers of warcraft fans are settling in the games online worldhalo has proved popular online with gamers notching up a record million hours playing the game on xbox livethe online game turns the stand alone warcraft games into a persistent world that players can inhabit not just visit europes gamers could be waiting until january to hear when they can get their mitts on nintendos handheld device nintendo ds says gamesindustrybizon the opening day of the world of warcraft massive multiplayer online game more than players signed up to playthe game has sold more than five million copies worldwide since it went on sale in midnovember the company saidaccording to microsoft nine out of xbox live members have played the game for an average of minutes per session\n",
      "\n",
      "Example 3:\n",
      "Generated: the <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "Reference: climate change could be completely out of control within several decades the scottish environment protection agency is warning a committee of mspsthe evidence is part of the committees inquiry into the impact of climate change in scotlandsepa predict that the two methods will remain as energy sources until climate change is under controlresearchers from the university of the highlands and islands and southampton have been looking at wave heights in the atlantic over the last nine yearsofficials believe nuclear energy and wind farms may be better options than trying to tackle global warmingexperts are giving evidence on the subject to the scottish parliaments environment committee\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import numpy as np\n",
    "\n",
    "def predict_summary(model, input_seq, summary_tok, max_len=20):\n",
    "    start_token = summary_tok.word_index.get('startseq', 1)\n",
    "    end_token = summary_tok.word_index.get('endseq', 2)\n",
    "    \n",
    "    decoder_input = np.zeros((1, max_len-1))\n",
    "    decoder_input[0, 0] = start_token\n",
    "    \n",
    "    for i in range(1, max_len-1):\n",
    "        pred = model.predict([input_seq, decoder_input], verbose=0)\n",
    "        next_token = np.argmax(pred[0, i-1, :])\n",
    "        \n",
    "        if next_token == end_token or next_token == 0:\n",
    "            break\n",
    "        decoder_input[0, i] = next_token\n",
    "    \n",
    "    reverse_word_map = {v: k for k, v in summary_tok.word_index.items()}\n",
    "    words = []\n",
    "    for token in decoder_input[0]:\n",
    "        if token != 0 and token in reverse_word_map:\n",
    "            word = reverse_word_map[token]\n",
    "            if word not in ['startseq', 'endseq']:\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "def evaluate_bleu(model, X_test, y_test, summary_tok, num_samples=100):\n",
    "    generated = []\n",
    "    references = []\n",
    "    \n",
    "    if hasattr(y_test, 'iloc'):\n",
    "        y_test = y_test.tolist()\n",
    "    \n",
    "    print(f\"Generating {num_samples} summaries...\")\n",
    "    for i in range(min(num_samples, len(X_test))):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Progress: {i}/{num_samples}\")\n",
    "        \n",
    "        pred_words = predict_summary(model, X_test[i:i+1], summary_tok)\n",
    "        ref_words = y_test[i].split()\n",
    "        \n",
    "        generated.append(pred_words)\n",
    "        references.append([ref_words])\n",
    "    \n",
    "    bleu_score = corpus_bleu(references, generated)\n",
    "    print(f\"\\nBLEU Score: {bleu_score:.4f}\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Generated: {' '.join(generated[i])}\")\n",
    "        print(f\"Reference: {' '.join(references[i][0])}\")\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"best_seq2seq.keras\")\n",
    "bleu_score = evaluate_bleu(model, X_test_pad, y_test, summary_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762b0b8",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "## The difference is clear here between the Transformer and the LSTM.\n",
    "## As the dataset is extremely small for such task with only 2225 samples. There is no space for even splitting on three train, dev and test.\n",
    "## The transformer was better in everything because it is pre-trained on huge amount of data and because of course transformers are generally better because of the way they use attention as we know ( Attention is all we need ). so, In general Transformers are way better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd792b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
